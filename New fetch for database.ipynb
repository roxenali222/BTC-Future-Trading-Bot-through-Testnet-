{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching new data from 2024 12 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 1000 candles, last timestamp: 2024-08-12 16:39:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-13 09:19:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-14 01:59:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-14 18:39:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-15 11:19:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-16 03:59:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-16 20:39:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-17 13:19:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-18 05:59:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-18 22:39:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-19 15:19:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-20 07:59:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-21 00:39:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-21 17:19:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-22 09:59:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-23 02:39:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-23 19:19:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-24 11:59:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-25 04:39:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-25 21:19:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-26 13:59:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-27 06:39:00\n",
      "Fetched 1000 candles, last timestamp: 2024-08-27 23:19:00\n",
      "Fetched 416 candles, last timestamp: 2024-08-28 06:15:00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ccxt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "api_key = os.getenv('BINANCE_API_KEY')\n",
    "secret_key = os.getenv('BINANCE_SECRET_KEY')\n",
    "exchange = ccxt.binance({\n",
    "    'apiKey': api_key,\n",
    "    'secret': secret_key,\n",
    "    'enableRateLimit': True,\n",
    "    'options': {\n",
    "        'defaultType': 'spot',\n",
    "        'test': True  \n",
    "    },\n",
    "})\n",
    "symbol = 'BTC/USDT'\n",
    "timeframe = '1m'  \n",
    "start_time = '2024-08-12T00:00:00Z'\n",
    "end_time = datetime.utcnow().isoformat()  \n",
    "start_timestamp = exchange.parse8601(start_time)\n",
    "end_timestamp = exchange.parse8601(end_time)\n",
    "def fetch_ohlcv(symbol, timeframe, since, end_timestamp, limit=1000):\n",
    "    ohlcv = []\n",
    "    while since < end_timestamp:\n",
    "        try:\n",
    "            candles = exchange.fetch_ohlcv(symbol, timeframe, since, limit)\n",
    "            if not candles:\n",
    "                break\n",
    "            ohlcv.extend(candles)\n",
    "            since = candles[-1][0] + 1 \n",
    "            print(f\"Fetched {len(candles)} candles, last timestamp: {pd.to_datetime(candles[-1][0], unit='ms')}\")\n",
    "        except ccxt.NetworkError as e:\n",
    "            print(f\"Network error: {e}\")\n",
    "            break\n",
    "        except ccxt.ExchangeError as e:\n",
    "            print(f\"Exchange error: {e}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            break\n",
    "    return ohlcv\n",
    "\n",
    "ohlcv_data = fetch_ohlcv(symbol, timeframe, start_timestamp, end_timestamp)\n",
    "\n",
    "df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df.to_csv('btc_1m_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "\n",
    "df = pd.read_csv('btc_1m_data.csv', parse_dates=['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Super_Trend_signal  EMA_signal  Hybrid_signal  \\\n",
      "timestamp                                                            \n",
      "2024-08-12 00:00:00                   1          -1             -1   \n",
      "2024-08-12 04:00:00                   1           1             -1   \n",
      "2024-08-12 08:00:00                   1           1             -1   \n",
      "2024-08-12 12:00:00                   1           1              1   \n",
      "2024-08-12 16:00:00                  -1           1             -1   \n",
      "...                                 ...         ...            ...   \n",
      "2024-08-27 12:00:00                  -1           1             -1   \n",
      "2024-08-27 16:00:00                  -1           1             -1   \n",
      "2024-08-27 20:00:00                  -1          -1             -1   \n",
      "2024-08-28 00:00:00                   1           1             -1   \n",
      "2024-08-28 04:00:00                  -1           1             -1   \n",
      "\n",
      "                     Stochastic_signal  BB_signal  \n",
      "timestamp                                          \n",
      "2024-08-12 00:00:00                 -1         -1  \n",
      "2024-08-12 04:00:00                 -1         -1  \n",
      "2024-08-12 08:00:00                 -1         -1  \n",
      "2024-08-12 12:00:00                  1         -1  \n",
      "2024-08-12 16:00:00                  1         -1  \n",
      "...                                ...        ...  \n",
      "2024-08-27 12:00:00                 -1         -1  \n",
      "2024-08-27 16:00:00                  1         -1  \n",
      "2024-08-27 20:00:00                 -1          1  \n",
      "2024-08-28 00:00:00                 -1         -1  \n",
      "2024-08-28 04:00:00                 -1         -1  \n",
      "\n",
      "[98 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MTariq\\AppData\\Local\\Temp\\ipykernel_16852\\394797738.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Super_Trend'].ffill(inplace=True)\n",
      "C:\\Users\\MTariq\\AppData\\Local\\Temp\\ipykernel_16852\\394797738.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Hybrid_signal'].fillna(-1, inplace=True)\n",
      "C:\\Users\\MTariq\\AppData\\Local\\Temp\\ipykernel_16852\\394797738.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Stochastic_signal'].fillna(-1, inplace=True)\n",
      "C:\\Users\\MTariq\\AppData\\Local\\Temp\\ipykernel_16852\\394797738.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['BB_signal'].fillna(-1, inplace=True)\n",
      "C:\\Users\\MTariq\\AppData\\Local\\Temp\\ipykernel_16852\\394797738.py:62: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  resampled_df = df.resample('4H').agg({\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def resample_signals(df):\n",
    "    # Super Trend\n",
    "    df['ATR'] = df['high'] - df['low']\n",
    "    df['ATR'] = df['ATR'].rolling(window=14).mean()\n",
    "    multiplier = 3\n",
    "    df['basic_upper_band'] = (df['high'] + df['low']) / 2 + multiplier * df['ATR']\n",
    "    df['basic_lower_band'] = (df['high'] + df['low']) / 2 - multiplier * df['ATR']\n",
    "    df['Super_Trend'] = df['basic_upper_band'].where(df['close'] > df['basic_upper_band'].shift(1),\n",
    "                                                     df['basic_lower_band'].where(df['close'] < df['basic_lower_band'].shift(1)))\n",
    "    df['Super_Trend'].ffill(inplace=True)\n",
    "    df['Super_Trend_signal'] = np.where(df['close'] > df['Super_Trend'], 1, -1)\n",
    "\n",
    "    # EMA\n",
    "    df['EMA'] = df['close'].ewm(span=20, adjust=False).mean()\n",
    "    df['EMA_signal'] = np.where(df['close'] > df['EMA'], 1, -1)\n",
    "\n",
    "    # Hybrid Indicator\n",
    "    donchian_period = 20\n",
    "    df['Donchian_High'] = df['high'].rolling(window=donchian_period).max()\n",
    "    df['Donchian_Low'] = df['low'].rolling(window=donchian_period).min()\n",
    "    df['cumulative_volume'] = df['volume'].cumsum()\n",
    "    df['cumulative_price_volume'] = (df['close'] * df['volume']).cumsum()\n",
    "    df['VWAP'] = df['cumulative_price_volume'] / df['cumulative_volume']\n",
    "    moving_average_period = 50\n",
    "    df['Moving_Avg'] = df['close'].rolling(window=moving_average_period).mean()\n",
    "    df['Breadth_Indicator'] = np.where(df['close'] > df['Moving_Avg'], 1, 0)\n",
    "    \n",
    "    df['Hybrid_signal'] = np.where(\n",
    "        (df['close'] > df['Donchian_High'].shift(1)) & (df['close'] > df['VWAP']) & (df['Breadth_Indicator'] == 1), 1,\n",
    "        np.where(\n",
    "            (df['close'] < df['Donchian_Low'].shift(1)) & (df['close'] < df['VWAP']) & (df['Breadth_Indicator'] == 0), -1, np.nan\n",
    "        )\n",
    "    )\n",
    "    df['Hybrid_signal'].fillna(-1, inplace=True)\n",
    "    df['Hybrid_signal'] = df['Hybrid_signal'].astype(int)\n",
    "\n",
    "    # Stochastic Oscillator\n",
    "    n = 14\n",
    "    df['Lowest_Low'] = df['low'].rolling(window=n).min()\n",
    "    df['Highest_High'] = df['high'].rolling(window=n).max()\n",
    "    df['%K'] = ((df['close'] - df['Lowest_Low']) / (df['Highest_High'] - df['Lowest_Low'])) * 100\n",
    "    df['%D'] = df['%K'].rolling(window=3).mean()\n",
    "\n",
    "    df['Stochastic_signal'] = np.where(\n",
    "        (df['%K'] > df['%D']) & (df['%K'].shift(1) <= df['%D'].shift(1)), 1,\n",
    "        np.where(\n",
    "            (df['%K'] < df['%D']) & (df['%K'].shift(1) >= df['%D'].shift(1)), -1, np.nan\n",
    "        )\n",
    "    )\n",
    "    df['Stochastic_signal'].fillna(-1, inplace=True)\n",
    "    df['Stochastic_signal'] = df['Stochastic_signal'].astype(int)\n",
    "\n",
    "    # Bollinger Bands\n",
    "    window = 20\n",
    "    no_of_std = 2\n",
    "    df['MA'] = df['close'].rolling(window=window).mean()\n",
    "    df['BB_Upper'] = df['MA'] + (df['close'].rolling(window=window).std() * no_of_std)\n",
    "    df['BB_Lower'] = df['MA'] - (df['close'].rolling(window=window).std() * no_of_std)\n",
    "    df['BB_signal'] = np.where(df['close'] < df['BB_Lower'], 1, np.where(df['close'] > df['BB_Upper'], -1, np.nan))\n",
    "    df['BB_signal'].fillna(-1, inplace=True)\n",
    "    df['BB_signal'] = df['BB_signal'].astype(int)\n",
    "    resampled_df = df.resample('4H').agg({\n",
    "        'Super_Trend_signal': 'last',\n",
    "        'EMA_signal': 'last',\n",
    "        'Hybrid_signal': 'last',\n",
    "        'Stochastic_signal': 'last',\n",
    "        'BB_signal': 'last'\n",
    "    }).dropna()\n",
    "\n",
    "    return resampled_df\n",
    "resampled_df = resample_signals(df)\n",
    "print(resampled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insterting signals to the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "def convert_timestamps(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    df['timestamp'] = df['timestamp'].astype(str)\n",
    "    return df\n",
    "conn = sqlite3.connect('indicators.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Indicators (\n",
    "    date_time TEXT PRIMARY KEY,\n",
    "    Super_Trend_signal INTEGER,\n",
    "    EMA_signal INTEGER,\n",
    "    Hybrid_signal INTEGER,\n",
    "    Stochastic_signal INTEGER,\n",
    "    BB_signal INTEGER\n",
    ")\n",
    "''')\n",
    "def insert_data(df):\n",
    "    df = convert_timestamps(df) \n",
    "    data = df.values.tolist()\n",
    "    cursor.executemany('''\n",
    "    INSERT OR REPLACE INTO Indicators (date_time, Super_Trend_signal, EMA_signal, Hybrid_signal, Stochastic_signal, BB_signal)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "    ''', data)\n",
    "    conn.commit()\n",
    "insert_data(resampled_df)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual vs Predicted values:\n",
      "                            y  yhat\n",
      "ds                                 \n",
      "2024-08-12 00:00:00  58722.99   NaN\n",
      "2024-08-12 00:01:00  58675.56   NaN\n",
      "2024-08-12 00:02:00  58720.01   NaN\n",
      "2024-08-12 00:03:00  58796.29   NaN\n",
      "2024-08-12 00:04:00  58767.12   NaN\n",
      "2024-08-12 00:05:00  58810.51   NaN\n",
      "2024-08-12 00:06:00  58817.99   NaN\n",
      "2024-08-12 00:07:00  58772.72   NaN\n",
      "2024-08-12 00:08:00  58799.84   NaN\n",
      "2024-08-12 00:09:00  58803.98   NaN\n",
      "Generated Signals:\n",
      "FB_signal\n",
      "-1    23416\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MTariq\\AppData\\Local\\Temp\\ipykernel_1536\\533212131.py:39: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  resampled_signals = prophet_df['FB_signal'].resample('4H').last().dropna()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from prophet.serialize import model_from_json\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('btc_1m_data.csv', parse_dates=['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Load Prophet Model\n",
    "with open('prophet_model.json', 'r') as f:\n",
    "    prophet_model = model_from_json(f.read())\n",
    "\n",
    "# Function to generate predictions and signals\n",
    "def generate_fb_signals(df):\n",
    "    # Prepare data for Prophet\n",
    "    prophet_df = df.reset_index()[['timestamp', 'close']].rename(columns={'timestamp': 'ds', 'close': 'y'})\n",
    "\n",
    "    # Predict the future using the Prophet model\n",
    "    future = prophet_model.make_future_dataframe(periods=0, freq='1min')\n",
    "    forecast = prophet_model.predict(future)\n",
    "\n",
    "    # Merge predictions with the original data\n",
    "    prophet_df = prophet_df.merge(forecast[['ds', 'yhat']], on='ds', how='left')\n",
    "    prophet_df.set_index('ds', inplace=True)\n",
    "\n",
    "    # Check the first few rows to see the actual vs predicted values\n",
    "    print(\"Actual vs Predicted values:\")\n",
    "    print(prophet_df[['y', 'yhat']].head(10))  # Adjust this as needed to view more values\n",
    "\n",
    "    # Generate Buy (1) and Sell (-1) signals\n",
    "    prophet_df['FB_signal'] = np.where(prophet_df['y'] > prophet_df['yhat'], 1, -1)\n",
    "\n",
    "    # Check signals generated\n",
    "    print(\"Generated Signals:\")\n",
    "    print(prophet_df['FB_signal'].value_counts())  # Check the distribution of 1 and -1\n",
    "\n",
    "    # Resample to 4-hour intervals, taking the last signal within each interval\n",
    "    resampled_signals = prophet_df['FB_signal'].resample('4H').last().dropna()\n",
    "\n",
    "    return resampled_signals\n",
    "\n",
    "# Generate signals\n",
    "fb_signals = generate_fb_signals(df)\n",
    "\n",
    "# Function to check if a column exists in the SQLite table\n",
    "def column_exists(cursor, table_name, column_name):\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = [info[1] for info in cursor.fetchall()]\n",
    "    return column_name in columns\n",
    "\n",
    "# Function to append signals to SQLite database\n",
    "def append_signals_to_db(signals, db_name='indicators.db', table_name='indicators', column_name='FB_signal'):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Check if the column exists, if not, add it\n",
    "    if not column_exists(cursor, table_name, column_name):\n",
    "        cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN {column_name} INTEGER\")\n",
    "\n",
    "    # Iterate over signals and update the database\n",
    "    for timestamp, signal in signals.items():\n",
    "        # Convert Timestamp to string format 'YYYY-MM-DD HH:MM:SS' to match the 'date_time' column format\n",
    "        timestamp_str = timestamp.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        cursor.execute(f\"\"\"\n",
    "        UPDATE {table_name}\n",
    "        SET {column_name} = ?\n",
    "        WHERE date_time = ?\n",
    "        \"\"\", (signal, timestamp_str))\n",
    "\n",
    "    # Commit changes and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Append signals to the database\n",
    "append_signals_to_db(fb_signals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
