{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB 4Houre Signal Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model weights loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading GRU model weights: A total of 3 objects could not be loaded. Example error message for object <GRUCell name=gru_cell, built=True>:\n",
      "\n",
      "Layer 'gru_cell' expected 3 variables, but received 0 variables during loading. Expected: ['kernel', 'recurrent_kernel', 'bias']\n",
      "\n",
      "List of objects that could not be loaded:\n",
      "[<GRUCell name=gru_cell, built=True>, <GRUCell name=gru_cell, built=True>, <Dense name=dense_7, built=True>]\n",
      "Prophet model loaded successfully.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Error generating Prophet signals: Dataframe has no rows.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional, got ndarray of shape (480, 480) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 205\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Run the scheduler\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[43mschedule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:854\u001b[0m, in \u001b[0;36mrun_pending\u001b[1;34m()\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_pending\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls :meth:`run_pending <Scheduler.run_pending>` on the\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;124;03m    :data:`default scheduler instance <default_scheduler>`.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 854\u001b[0m     \u001b[43mdefault_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:101\u001b[0m, in \u001b[0;36mScheduler.run_pending\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m runnable_jobs \u001b[38;5;241m=\u001b[39m (job \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs \u001b[38;5;28;01mif\u001b[39;00m job\u001b[38;5;241m.\u001b[39mshould_run)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(runnable_jobs):\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:173\u001b[0m, in \u001b[0;36mScheduler._run_job\u001b[1;34m(self, job)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, CancelJob) \u001b[38;5;129;01mor\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m CancelJob:\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_job(job)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:691\u001b[0m, in \u001b[0;36mJob.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CancelJob\n\u001b[0;32m    690\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning job \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 691\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_run \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule_next_run()\n",
      "Cell \u001b[1;32mIn[1], line 181\u001b[0m, in \u001b[0;36mrun_process\u001b[1;34m()\u001b[0m\n\u001b[0;32m    178\u001b[0m hybrid_signal \u001b[38;5;241m=\u001b[39m calculate_hybrid_signal(df)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Generate model-based signals (pass the models as arguments)\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m model_signals_df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_model_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgru_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprophet_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for indicator signals\u001b[39;00m\n\u001b[0;32m    184\u001b[0m indicator_signals \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: [df\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]],\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuper_Trend_signal\u001b[39m\u001b[38;5;124m'\u001b[39m: [super_trend_signal],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHybrid_signal\u001b[39m\u001b[38;5;124m'\u001b[39m: [hybrid_signal]\n\u001b[0;32m    191\u001b[0m })\n",
      "Cell \u001b[1;32mIn[4], line 158\u001b[0m, in \u001b[0;36mgenerate_model_signals\u001b[1;34m(df, lstm_model, gru_model, prophet_model)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError generating Prophet signals: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLSTM_Signals\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_signal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGRU_Signals\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgru_signal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFB_signal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprophet_signal\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:629\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    626\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[0;32m    627\u001b[0m     val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m--> 629\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m com\u001b[38;5;241m.\u001b[39mrequire_length_match(val, index)\n\u001b[0;32m    631\u001b[0m refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\construction.py:659\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    656\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[0;32m    657\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 659\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    663\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\construction.py:718\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    720\u001b[0m     )\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (480, 480) instead"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import time\n",
    "import schedule\n",
    "from binance.client import Client\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from datetime import datetime\n",
    "from prophet import Prophet\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# API keys\n",
    "api_key = 'dd1a2703da01c24ccdbe10b2cbc9600a6218c41434d4453916766e1e817aabfe'\n",
    "api_secret = '2acb5c37db3c5646fdadb366cacb5d9a11ffe05d7b4d01dfb1b3047f2a2ea09a'\n",
    "\n",
    "# Initialize Binance client\n",
    "client = Client(api_key, api_secret, testnet=True)\n",
    "\n",
    "# Define LSTM model architecture\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Define GRU model architecture\n",
    "def create_gru_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(128, activation='relu', return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(64, activation='relu', return_sequences=False))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "\n",
    "# Load pre-trained models\n",
    "def load_models():\n",
    "    try:\n",
    "        lstm_model = create_lstm_model((20, 1))\n",
    "        lstm_model.load_weights('lstmw.weights.h5')\n",
    "        print(\"LSTM model weights loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading LSTM model weights: {e}\")\n",
    "        lstm_model = None\n",
    "\n",
    "    try:\n",
    "        gru_model = create_gru_model((10, 1))\n",
    "        gru_model.load_weights('model.weights.h5')\n",
    "        print(\"GRU model weights loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading GRU model weights: {e}\")\n",
    "        gru_model = None\n",
    "\n",
    "    try:\n",
    "        prophet_model = load_prophet_model('prophet_model.json')\n",
    "        print(\"Prophet model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Prophet model: {e}\")\n",
    "        prophet_model = None\n",
    "\n",
    "    return lstm_model, gru_model, prophet_model\n",
    "\n",
    "def load_prophet_model(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        model_json = f.read()\n",
    "    model = Prophet()\n",
    "    model.__dict__.update(json.loads(model_json))\n",
    "    return model\n",
    "\n",
    "# Fetch data from Binance\n",
    "def fetch_binance_data(start_date, end_date):\n",
    "    klines = client.futures_klines(symbol='BTCUSDT', interval='1m', start_str=start_date, end_str=end_date)\n",
    "    df = pd.DataFrame(klines, columns=['date_time', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'])\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], unit='ms')\n",
    "    df.set_index('date_time', inplace=True)\n",
    "    df = df[['open', 'high', 'low', 'close', 'volume']].astype(float)\n",
    "    return df\n",
    "\n",
    "# Prepare sequences for model prediction\n",
    "def prepare_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i + sequence_length])\n",
    "    return np.array(sequences)\n",
    "\n",
    "# Calculate indicators\n",
    "def calculate_super_trend(data, atr_period=10, multiplier=3):\n",
    "    data['H-L'] = data['high'] - data['low']\n",
    "    data['H-PC'] = np.abs(data['high'] - data['close'].shift(1))\n",
    "    data['L-PC'] = np.abs(data['low'] - data['close'].shift(1))\n",
    "    data['TR'] = data[['H-L', 'H-PC', 'L-PC']].max(axis=1)\n",
    "    data['ATR'] = data['TR'].rolling(window=atr_period).mean()\n",
    "    data['Upper Band'] = (data['high'] + data['low']) / 2 + (multiplier * data['ATR'])\n",
    "    data['Lower Band'] = (data['high'] + data['low']) / 2 - (multiplier * data['ATR'])\n",
    "    data['Super_Trend'] = np.where(data['close'] > data['Upper Band'], 1, -1)\n",
    "    return data['Super_Trend'].iloc[-1]\n",
    "\n",
    "def calculate_ema_signal(data, period=14):\n",
    "    data['EMA'] = data['close'].ewm(span=period, adjust=False).mean()\n",
    "    return 1 if data['close'].iloc[-1] > data['EMA'].iloc[-1] else -1\n",
    "\n",
    "def calculate_stochastic_signal(data, period=14):\n",
    "    data['Low_Min'] = data['low'].rolling(window=period).min()\n",
    "    data['High_Max'] = data['high'].rolling(window=period).max()\n",
    "    data['%K'] = (data['close'] - data['Low_Min']) * 100 / (data['High_Max'] - data['Low_Min'])\n",
    "    data['%D'] = data['%K'].rolling(window=3).mean()\n",
    "    return 1 if data['%K'].iloc[-1] > data['%D'].iloc[-1] else -1\n",
    "\n",
    "def calculate_bollinger_bands_signal(data, period=20, std_dev=2):\n",
    "    data['SMA'] = data['close'].rolling(window=period).mean()\n",
    "    data['Upper_Band'] = data['SMA'] + std_dev * data['close'].rolling(window=period).std()\n",
    "    data['Lower_Band'] = data['SMA'] - std_dev * data['close'].rolling(window=period).std()\n",
    "    return 1 if data['close'].iloc[-1] > data['Upper_Band'].iloc[-1] else -1\n",
    "\n",
    "def calculate_hybrid_signal(data):\n",
    "    super_trend_signal = calculate_super_trend(data)\n",
    "    ema_signal = calculate_ema_signal(data)\n",
    "    return 1 if super_trend_signal == 1 and ema_signal == 1 else -1\n",
    "\n",
    "# Generate model-based signals\n",
    "def generate_model_signals(df, lstm_model, gru_model, prophet_model):\n",
    "    close_prices = df['close'].values\n",
    "    sequences = prepare_sequences(close_prices, sequence_length=20)\n",
    "\n",
    "    lstm_signal = np.zeros(len(close_prices))\n",
    "    gru_signal = np.zeros(len(close_prices))\n",
    "    prophet_signal = np.zeros(len(close_prices))\n",
    "\n",
    "    if lstm_model:\n",
    "        try:\n",
    "            lstm_pred = lstm_model.predict(sequences)\n",
    "            lstm_signal = np.where(lstm_pred > df['close'].iloc[-len(lstm_pred):].values, 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating LSTM signals: {e}\")\n",
    "\n",
    "    if gru_model:\n",
    "        try:\n",
    "            gru_pred = gru_model.predict(sequences)\n",
    "            gru_signal = np.where(gru_pred > df['close'].iloc[-len(gru_pred):].values, 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating GRU signals: {e}\")\n",
    "\n",
    "    if prophet_model:\n",
    "        try:\n",
    "            future_dates = pd.DataFrame(df.index, columns=['ds'])\n",
    "            prophet_forecast = prophet_model.predict(future_dates)\n",
    "            prophet_signal = np.where(prophet_forecast['yhat'] > df['close'].values, 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating Prophet signals: {e}\")\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'LSTM_Signals': lstm_signal,\n",
    "        'GRU_Signals': gru_signal,\n",
    "        'FB_signal': prophet_signal\n",
    "    }, index=df.index)\n",
    "\n",
    "# Append signals to the SQL database\n",
    "def append_signals_to_db(signals_df):\n",
    "    conn = sqlite3.connect('indicators.db')\n",
    "    signals_df.to_sql('indicators', conn, if_exists='append', index=True)\n",
    "    conn.close()\n",
    "\n",
    "# Main process\n",
    "def run_process():\n",
    "    lstm_model, gru_model, prophet_model = load_models()\n",
    "\n",
    "    start_date = '2024-08-12 00:00:00'\n",
    "    end_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df = fetch_binance_data(start_date, end_date)\n",
    "\n",
    "    # Generate indicator-based signals\n",
    "    super_trend_signal = calculate_super_trend(df)\n",
    "    ema_signal = calculate_ema_signal(df)\n",
    "    stochastic_signal = calculate_stochastic_signal(df)\n",
    "    bollinger_signal = calculate_bollinger_bands_signal(df)\n",
    "    hybrid_signal = calculate_hybrid_signal(df)\n",
    "\n",
    "    # Generate model-based signals\n",
    "    model_signals = generate_model_signals(df, lstm_model, gru_model, prophet_model)\n",
    "    \n",
    "    # Combine all signals into one DataFrame\n",
    "    all_signals_df = pd.concat([model_signals, \n",
    "                                pd.DataFrame({'Super_Trend': super_trend_signal, 'EMA_Signal': ema_signal, \n",
    "                                              'Stochastic_Signal': stochastic_signal, 'Bollinger_Signal': bollinger_signal,\n",
    "                                              'Hybrid_Signal': hybrid_signal}, index=df.index)], axis=1)\n",
    "\n",
    "    # Save to CSV file\n",
    "    all_signals_df.to_csv('combined_signals.csv')\n",
    "\n",
    "    # Append to SQLite DB\n",
    "    append_signals_to_db(all_signals_df)\n",
    "\n",
    "# Schedule the script to run every 4 hours\n",
    "schedule.every(4).hours.do(run_process)\n",
    "\n",
    "# Run the scheduler\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Some Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model weights loaded successfully.\n",
      "Error loading GRU model weights: [Errno 2] Unable to synchronously open file (unable to open file: name = 'gru_model.weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Error loading Prophet model: 'Prophet' object has no attribute 'load'\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional, got ndarray of shape (480, 480) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 119\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Run the Scheduler\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[43mschedule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:854\u001b[0m, in \u001b[0;36mrun_pending\u001b[1;34m()\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_pending\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls :meth:`run_pending <Scheduler.run_pending>` on the\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;124;03m    :data:`default scheduler instance <default_scheduler>`.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 854\u001b[0m     \u001b[43mdefault_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:101\u001b[0m, in \u001b[0;36mScheduler.run_pending\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m runnable_jobs \u001b[38;5;241m=\u001b[39m (job \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs \u001b[38;5;28;01mif\u001b[39;00m job\u001b[38;5;241m.\u001b[39mshould_run)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(runnable_jobs):\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:173\u001b[0m, in \u001b[0;36mScheduler._run_job\u001b[1;34m(self, job)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, CancelJob) \u001b[38;5;129;01mor\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m CancelJob:\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_job(job)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:691\u001b[0m, in \u001b[0;36mJob.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CancelJob\n\u001b[0;32m    690\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning job \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 691\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_run \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule_next_run()\n",
      "Cell \u001b[1;32mIn[1], line 181\u001b[0m, in \u001b[0;36mrun_process\u001b[1;34m()\u001b[0m\n\u001b[0;32m    178\u001b[0m hybrid_signal \u001b[38;5;241m=\u001b[39m calculate_hybrid_signal(df)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Generate model-based signals (pass the models as arguments)\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m model_signals_df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_model_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgru_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprophet_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for indicator signals\u001b[39;00m\n\u001b[0;32m    184\u001b[0m indicator_signals \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: [df\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]],\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuper_Trend_signal\u001b[39m\u001b[38;5;124m'\u001b[39m: [super_trend_signal],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHybrid_signal\u001b[39m\u001b[38;5;124m'\u001b[39m: [hybrid_signal]\n\u001b[0;32m    191\u001b[0m })\n",
      "Cell \u001b[1;32mIn[7], line 98\u001b[0m, in \u001b[0;36mgenerate_model_signals\u001b[1;34m(df, lstm_model, gru_model, prophet_model)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError generating Prophet signals: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLSTM_Signals\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_signal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGRU_Signals\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgru_signal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFB_signal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprophet_signal\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:629\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    626\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[0;32m    627\u001b[0m     val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m--> 629\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m com\u001b[38;5;241m.\u001b[39mrequire_length_match(val, index)\n\u001b[0;32m    631\u001b[0m refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\construction.py:659\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    656\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[0;32m    657\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 659\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    663\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\construction.py:718\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    720\u001b[0m     )\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (480, 480) instead"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Input\n",
    "from prophet import Prophet\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# Model Definitions\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def create_gru_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(128, activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(64, activation='relu', return_sequences=False))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "\n",
    "# Load Models\n",
    "def load_models():\n",
    "    try:\n",
    "        lstm_model = create_lstm_model((20, 1))\n",
    "        lstm_model.load_weights('lstmw.weights.h5')\n",
    "        print(\"LSTM model weights loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading LSTM model weights: {e}\")\n",
    "        lstm_model = None\n",
    "\n",
    "    try:\n",
    "        gru_model = create_gru_model((10, 1))\n",
    "        gru_model.load_weights('gru_model.weights.h5')\n",
    "        print(\"GRU model weights loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading GRU model weights: {e}\")\n",
    "        gru_model = None\n",
    "\n",
    "    try:\n",
    "        prophet_model = Prophet()\n",
    "        prophet_model.load('prophet_model.pkl')\n",
    "        print(\"Prophet model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Prophet model: {e}\")\n",
    "        prophet_model = None\n",
    "\n",
    "    return lstm_model, gru_model, prophet_model\n",
    "\n",
    "# Prepare Sequences\n",
    "def prepare_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i + sequence_length])\n",
    "    return np.array(sequences).reshape(-1, sequence_length, 1)\n",
    "\n",
    "# Generate Model Signals\n",
    "def generate_model_signals(df, lstm_model, gru_model, prophet_model):\n",
    "    close_prices = df['close'].values\n",
    "    sequences = prepare_sequences(close_prices, sequence_length=20)\n",
    "\n",
    "    lstm_signal = np.zeros(len(close_prices))\n",
    "    gru_signal = np.zeros(len(close_prices))\n",
    "    prophet_signal = np.zeros(len(close_prices))\n",
    "\n",
    "    if lstm_model:\n",
    "        try:\n",
    "            lstm_pred = lstm_model.predict(sequences)\n",
    "            lstm_signal = np.where(lstm_pred > df['close'].iloc[-len(lstm_pred):].values, 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating LSTM signals: {e}\")\n",
    "\n",
    "    if gru_model:\n",
    "        try:\n",
    "            gru_pred = gru_model.predict(sequences)\n",
    "            gru_signal = np.where(gru_pred > df['close'].iloc[-len(gru_pred):].values, 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating GRU signals: {e}\")\n",
    "\n",
    "    if prophet_model:\n",
    "        try:\n",
    "            future_dates = pd.DataFrame(df.index, columns=['ds'])\n",
    "            prophet_forecast = prophet_model.predict(future_dates)\n",
    "            prophet_signal = np.where(prophet_forecast['yhat'] > df['close'].values, 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating Prophet signals: {e}\")\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'LSTM_Signals': lstm_signal,\n",
    "        'GRU_Signals': gru_signal,\n",
    "        'FB_signal': prophet_signal\n",
    "    }, index=df.index)\n",
    "\n",
    "# Scheduler Task\n",
    "def job():\n",
    "    df = pd.read_csv('data.csv')  # Replace with actual data loading\n",
    "    lstm_model, gru_model, prophet_model = load_models()\n",
    "    if lstm_model is not None and gru_model is not None and prophet_model is not None:\n",
    "        signals_df = generate_model_signals(df, lstm_model, gru_model, prophet_model)\n",
    "        signals_df.to_csv('model_signals.csv')\n",
    "    else:\n",
    "        print(\"Not all models are loaded successfully.\")\n",
    "\n",
    "# Schedule Task\n",
    "schedule.every().hour.do(job)\n",
    "\n",
    "# Run the Scheduler\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model weights loaded successfully.\n",
      "Error loading GRU model weights: [Errno 2] Unable to synchronously open file (unable to open file: name = 'gru_model.weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Error loading Prophet model: 'Prophet' object has no attribute 'load'\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional, got ndarray of shape (480, 480) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 119\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Run the Scheduler\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[43mschedule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:854\u001b[0m, in \u001b[0;36mrun_pending\u001b[1;34m()\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_pending\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls :meth:`run_pending <Scheduler.run_pending>` on the\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;124;03m    :data:`default scheduler instance <default_scheduler>`.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 854\u001b[0m     \u001b[43mdefault_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:101\u001b[0m, in \u001b[0;36mScheduler.run_pending\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m runnable_jobs \u001b[38;5;241m=\u001b[39m (job \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs \u001b[38;5;28;01mif\u001b[39;00m job\u001b[38;5;241m.\u001b[39mshould_run)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(runnable_jobs):\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:173\u001b[0m, in \u001b[0;36mScheduler._run_job\u001b[1;34m(self, job)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, CancelJob) \u001b[38;5;129;01mor\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m CancelJob:\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_job(job)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:691\u001b[0m, in \u001b[0;36mJob.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CancelJob\n\u001b[0;32m    690\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning job \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 691\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_run \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule_next_run()\n",
      "Cell \u001b[1;32mIn[1], line 181\u001b[0m, in \u001b[0;36mrun_process\u001b[1;34m()\u001b[0m\n\u001b[0;32m    178\u001b[0m hybrid_signal \u001b[38;5;241m=\u001b[39m calculate_hybrid_signal(df)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Generate model-based signals (pass the models as arguments)\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m model_signals_df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_model_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgru_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprophet_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for indicator signals\u001b[39;00m\n\u001b[0;32m    184\u001b[0m indicator_signals \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: [df\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]],\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuper_Trend_signal\u001b[39m\u001b[38;5;124m'\u001b[39m: [super_trend_signal],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHybrid_signal\u001b[39m\u001b[38;5;124m'\u001b[39m: [hybrid_signal]\n\u001b[0;32m    191\u001b[0m })\n",
      "Cell \u001b[1;32mIn[8], line 98\u001b[0m, in \u001b[0;36mgenerate_model_signals\u001b[1;34m(df, lstm_model, gru_model, prophet_model)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError generating Prophet signals: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLSTM_Signals\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_signal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGRU_Signals\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgru_signal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFB_signal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprophet_signal\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:629\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    626\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[0;32m    627\u001b[0m     val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m--> 629\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m com\u001b[38;5;241m.\u001b[39mrequire_length_match(val, index)\n\u001b[0;32m    631\u001b[0m refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\construction.py:659\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    656\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[0;32m    657\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 659\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    663\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\pandas\\core\\construction.py:718\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    720\u001b[0m     )\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (480, 480) instead"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Input\n",
    "from prophet import Prophet\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# Model Definitions\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def create_gru_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(128, activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(64, activation='relu', return_sequences=False))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "\n",
    "# Load Models\n",
    "def load_models():\n",
    "    try:\n",
    "        lstm_model = create_lstm_model((20, 1))\n",
    "        lstm_model.load_weights('lstmw.weights.h5')\n",
    "        print(\"LSTM model weights loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading LSTM model weights: {e}\")\n",
    "        lstm_model = None\n",
    "\n",
    "    try:\n",
    "        gru_model = create_gru_model((10, 1))\n",
    "        gru_model.load_weights('gru_model.weights.h5')\n",
    "        print(\"GRU model weights loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading GRU model weights: {e}\")\n",
    "        gru_model = None\n",
    "\n",
    "    try:\n",
    "        prophet_model = Prophet()\n",
    "        prophet_model.load('prophet_model.pkl')\n",
    "        print(\"Prophet model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Prophet model: {e}\")\n",
    "        prophet_model = None\n",
    "\n",
    "    return lstm_model, gru_model, prophet_model\n",
    "\n",
    "# Prepare Sequences\n",
    "def prepare_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i + sequence_length])\n",
    "    return np.array(sequences).reshape(-1, sequence_length, 1)\n",
    "\n",
    "# Generate Model Signals\n",
    "def generate_model_signals(df, lstm_model, gru_model, prophet_model):\n",
    "    close_prices = df['close'].values\n",
    "    sequences = prepare_sequences(close_prices, sequence_length=20)\n",
    "\n",
    "    lstm_signal = np.zeros(len(close_prices))\n",
    "    gru_signal = np.zeros(len(close_prices))\n",
    "    prophet_signal = np.zeros(len(close_prices))\n",
    "\n",
    "    if lstm_model:\n",
    "        try:\n",
    "            lstm_pred = lstm_model.predict(sequences)\n",
    "            lstm_signal = np.where(lstm_pred > df['close'].iloc[-len(lstm_pred):].values, 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating LSTM signals: {e}\")\n",
    "\n",
    "    if gru_model:\n",
    "        try:\n",
    "            gru_pred = gru_model.predict(sequences)\n",
    "            gru_signal = np.where(gru_pred > df['close'].iloc[-len(gru_pred):].values, 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating GRU signals: {e}\")\n",
    "\n",
    "    if prophet_model:\n",
    "        try:\n",
    "            future_dates = pd.DataFrame(df.index, columns=['ds'])\n",
    "            prophet_forecast = prophet_model.predict(future_dates)\n",
    "            prophet_signal = np.where(prophet_forecast['yhat'] > df['close'].values, 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating Prophet signals: {e}\")\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'LSTM_Signals': lstm_signal,\n",
    "        'GRU_Signals': gru_signal,\n",
    "        'FB_signal': prophet_signal\n",
    "    }, index=df.index)\n",
    "\n",
    "# Scheduler Task\n",
    "def job():\n",
    "    df = pd.read_csv('data.csv')  # Replace with actual data loading\n",
    "    lstm_model, gru_model, prophet_model = load_models()\n",
    "    if lstm_model is not None and gru_model is not None and prophet_model is not None:\n",
    "        signals_df = generate_model_signals(df, lstm_model, gru_model, prophet_model)\n",
    "        signals_df.to_csv('model_signals.csv')\n",
    "    else:\n",
    "        print(\"Not all models are loaded successfully.\")\n",
    "\n",
    "# Schedule Task\n",
    "schedule.every().hour.do(job)\n",
    "\n",
    "# Run the Scheduler\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_model_signals() missing 3 required positional arguments: 'lstm_model', 'gru_model', and 'prophet_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Run the process\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mschedule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:854\u001b[0m, in \u001b[0;36mrun_pending\u001b[1;34m()\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_pending\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls :meth:`run_pending <Scheduler.run_pending>` on the\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;124;03m    :data:`default scheduler instance <default_scheduler>`.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 854\u001b[0m     \u001b[43mdefault_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:101\u001b[0m, in \u001b[0;36mScheduler.run_pending\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m runnable_jobs \u001b[38;5;241m=\u001b[39m (job \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs \u001b[38;5;28;01mif\u001b[39;00m job\u001b[38;5;241m.\u001b[39mshould_run)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(runnable_jobs):\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:173\u001b[0m, in \u001b[0;36mScheduler._run_job\u001b[1;34m(self, job)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, CancelJob) \u001b[38;5;129;01mor\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m CancelJob:\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_job(job)\n",
      "File \u001b[1;32mc:\\Users\\MTariq\\Downloads\\python-binance-master\\Desktop\\python-binance-master\\tests\\.conda\\Lib\\site-packages\\schedule\\__init__.py:691\u001b[0m, in \u001b[0;36mJob.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CancelJob\n\u001b[0;32m    690\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning job \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 691\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_run \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule_next_run()\n",
      "Cell \u001b[1;32mIn[4], line 137\u001b[0m, in \u001b[0;36mrun_process\u001b[1;34m()\u001b[0m\n\u001b[0;32m    129\u001b[0m indicator_signals \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuper_Trend_signal\u001b[39m\u001b[38;5;124m'\u001b[39m: [super_trend_signal],\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMA_signal\u001b[39m\u001b[38;5;124m'\u001b[39m: [ema_signal],\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStochastic_signal\u001b[39m\u001b[38;5;124m'\u001b[39m: [stochastic_signal],\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBB_signal\u001b[39m\u001b[38;5;124m'\u001b[39m: [bollinger_bands_signal]\n\u001b[0;32m    134\u001b[0m }, index\u001b[38;5;241m=\u001b[39m[df\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Generate model-based signals\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m model_signals \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_model_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# Combine signals into a single DataFrame\u001b[39;00m\n\u001b[0;32m    140\u001b[0m combined_signals \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([indicator_signals, model_signals], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: generate_model_signals() missing 3 required positional arguments: 'lstm_model', 'gru_model', and 'prophet_model'"
     ]
    }
   ],
   "source": [
    "import schedule\n",
    "import time\n",
    "\n",
    "# Scheduler to run every 4 hours\n",
    "schedule.every(4).hours.do(run_process)\n",
    "\n",
    "# Run the process\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_signals(df, lstm_model, gru_model, prophet_model):\n",
    "    close_prices = df['close'].values\n",
    "    sequences = prepare_sequences(close_prices)\n",
    "\n",
    "    # Initialize signal arrays\n",
    "    lstm_signal = np.zeros(len(close_prices))\n",
    "    gru_signal = np.zeros(len(close_prices))\n",
    "    prophet_signal = np.zeros(len(close_prices))\n",
    "\n",
    "    # Generate LSTM model signals\n",
    "    if lstm_model:\n",
    "        try:\n",
    "            # Predict using LSTM\n",
    "            lstm_pred = lstm_model.predict(sequences)\n",
    "            # Generate signals based on prediction\n",
    "            lstm_signal[len(lstm_pred):] = np.where(lstm_pred > close_prices[:len(lstm_pred)], 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating LSTM signals: {e}\")\n",
    "\n",
    "    # Generate GRU model signals\n",
    "    if gru_model:\n",
    "        try:\n",
    "            # Predict using GRU\n",
    "            gru_pred = gru_model.predict(sequences)\n",
    "            # Generate signals based on prediction\n",
    "            gru_signal[len(gru_pred):] = np.where(gru_pred > close_prices[:len(gru_pred)], 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating GRU signals: {e}\")\n",
    "\n",
    "    # Generate Prophet model signals\n",
    "    if prophet_model:\n",
    "        try:\n",
    "            # Prepare data for Prophet\n",
    "            future_dates = pd.DataFrame(df.index, columns=['ds'])\n",
    "            prophet_forecast = prophet_model.predict(future_dates)\n",
    "            # Generate signals based on prediction\n",
    "            prophet_signal = np.where(prophet_forecast['yhat'] > close_prices, 1, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating Prophet signals: {e}\")\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'LSTM_Signals': lstm_signal,\n",
    "        'GRU_Signals': gru_signal,\n",
    "        'FB_signal': prophet_signal\n",
    "    }, index=df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:cmd: where.exe tbb.dll\n",
      "cwd: None\n",
      "DEBUG:cmdstanpy:TBB already found in load path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "import json\n",
    "\n",
    "def load_prophet_model(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        model_json = f.read()\n",
    "    model = Prophet()\n",
    "    # Load model configuration here\n",
    "    return model\n",
    "\n",
    "try:\n",
    "    prophet_model = load_prophet_model('prophet_model.json')\n",
    "    print(\"Prophet model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Prophet model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
