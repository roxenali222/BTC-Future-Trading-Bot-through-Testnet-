{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Indicator Signals Added to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('ohlc_1m_data_last_day.csv', parse_dates=['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MTariq\\AppData\\Local\\Temp\\ipykernel_12344\\550431303.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Super_Trend'].ffill(inplace=True)\n",
      "C:\\Users\\MTariq\\AppData\\Local\\Temp\\ipykernel_12344\\550431303.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Hybrid_signal'].fillna(-1, inplace=True)\n",
      "C:\\Users\\MTariq\\AppData\\Local\\Temp\\ipykernel_12344\\550431303.py:57: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Stochastic_signal'].fillna(-1, inplace=True)\n",
      "C:\\Users\\MTariq\\AppData\\Local\\Temp\\ipykernel_12344\\550431303.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['BB_signal'].fillna(-1, inplace=True)\n",
      "C:\\Users\\MTariq\\AppData\\Local\\Temp\\ipykernel_12344\\550431303.py:71: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  resampled_df = df.resample('4H').agg({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Super_Trend_signal  EMA_signal  Hybrid_signal  \\\n",
      "timestamp                                                            \n",
      "2020-01-01 00:00:00                  -1          -1             -1   \n",
      "2020-01-01 04:00:00                  -1          -1             -1   \n",
      "2020-01-01 08:00:00                   1          -1             -1   \n",
      "2020-01-01 12:00:00                  -1           1             -1   \n",
      "2020-01-01 16:00:00                  -1          -1             -1   \n",
      "...                                 ...         ...            ...   \n",
      "2024-08-11 08:00:00                   1           1             -1   \n",
      "2024-08-11 12:00:00                  -1          -1             -1   \n",
      "2024-08-11 16:00:00                   1          -1             -1   \n",
      "2024-08-11 20:00:00                  -1          -1             -1   \n",
      "2024-08-12 00:00:00                  -1          -1             -1   \n",
      "\n",
      "                     Stochastic_signal  BB_signal  \n",
      "timestamp                                          \n",
      "2020-01-01 00:00:00                 -1         -1  \n",
      "2020-01-01 04:00:00                 -1         -1  \n",
      "2020-01-01 08:00:00                 -1         -1  \n",
      "2020-01-01 12:00:00                 -1         -1  \n",
      "2020-01-01 16:00:00                  1         -1  \n",
      "...                                ...        ...  \n",
      "2024-08-11 08:00:00                 -1         -1  \n",
      "2024-08-11 12:00:00                 -1          1  \n",
      "2024-08-11 16:00:00                 -1         -1  \n",
      "2024-08-11 20:00:00                 -1         -1  \n",
      "2024-08-12 00:00:00                 -1          1  \n",
      "\n",
      "[10111 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def resample_signals(df):\n",
    "    # Super Trend\n",
    "    df['ATR'] = df['high'] - df['low']\n",
    "    df['ATR'] = df['ATR'].rolling(window=14).mean()\n",
    "    multiplier = 3\n",
    "    df['basic_upper_band'] = (df['high'] + df['low']) / 2 + multiplier * df['ATR']\n",
    "    df['basic_lower_band'] = (df['high'] + df['low']) / 2 - multiplier * df['ATR']\n",
    "    df['Super_Trend'] = df['basic_upper_band'].where(df['close'] > df['basic_upper_band'].shift(1),\n",
    "                                                     df['basic_lower_band'].where(df['close'] < df['basic_lower_band'].shift(1)))\n",
    "    df['Super_Trend'].ffill(inplace=True)\n",
    "    df['Super_Trend_signal'] = np.where(df['close'] > df['Super_Trend'], 1, -1)\n",
    "\n",
    "    # EMA\n",
    "    df['EMA'] = df['close'].ewm(span=20, adjust=False).mean()\n",
    "    df['EMA_signal'] = np.where(df['close'] > df['EMA'], 1, -1)\n",
    "\n",
    "    # Hybrid Indicator\n",
    "    donchian_period = 20\n",
    "    df['Donchian_High'] = df['high'].rolling(window=donchian_period).max()\n",
    "    df['Donchian_Low'] = df['low'].rolling(window=donchian_period).min()\n",
    "    df['cumulative_volume'] = df['volume'].cumsum()\n",
    "    df['cumulative_price_volume'] = (df['close'] * df['volume']).cumsum()\n",
    "    df['VWAP'] = df['cumulative_price_volume'] / df['cumulative_volume']\n",
    "    moving_average_period = 50\n",
    "    df['Moving_Avg'] = df['close'].rolling(window=moving_average_period).mean()\n",
    "    df['Breadth_Indicator'] = np.where(df['close'] > df['Moving_Avg'], 1, 0)\n",
    "    \n",
    "    df['Hybrid_signal'] = np.where(\n",
    "        (df['close'] > df['Donchian_High'].shift(1)) & (df['close'] > df['VWAP']) & (df['Breadth_Indicator'] == 1), 1,\n",
    "        np.where(\n",
    "            (df['close'] < df['Donchian_Low'].shift(1)) & (df['close'] < df['VWAP']) & (df['Breadth_Indicator'] == 0), -1, np.nan\n",
    "        )\n",
    "    )\n",
    "    df['Hybrid_signal'].fillna(-1, inplace=True)\n",
    "    df['Hybrid_signal'] = df['Hybrid_signal'].astype(int)\n",
    "\n",
    "    # Stochastic Oscillator\n",
    "    n = 14\n",
    "    df['Lowest_Low'] = df['low'].rolling(window=n).min()\n",
    "    df['Highest_High'] = df['high'].rolling(window=n).max()\n",
    "    df['%K'] = ((df['close'] - df['Lowest_Low']) / (df['Highest_High'] - df['Lowest_Low'])) * 100\n",
    "    df['%D'] = df['%K'].rolling(window=3).mean()\n",
    "\n",
    "    df['Stochastic_signal'] = np.where(\n",
    "        (df['%K'] > df['%D']) & (df['%K'].shift(1) <= df['%D'].shift(1)), 1,\n",
    "        np.where(\n",
    "            (df['%K'] < df['%D']) & (df['%K'].shift(1) >= df['%D'].shift(1)), -1, np.nan\n",
    "        )\n",
    "    )\n",
    "    df['Stochastic_signal'].fillna(-1, inplace=True)\n",
    "    df['Stochastic_signal'] = df['Stochastic_signal'].astype(int)\n",
    "\n",
    "    # Bollinger Bands\n",
    "    window = 20\n",
    "    no_of_std = 2\n",
    "    df['MA'] = df['close'].rolling(window=window).mean()\n",
    "    df['BB_Upper'] = df['MA'] + (df['close'].rolling(window=window).std() * no_of_std)\n",
    "    df['BB_Lower'] = df['MA'] - (df['close'].rolling(window=window).std() * no_of_std)\n",
    "    df['BB_signal'] = np.where(df['close'] < df['BB_Lower'], 1, np.where(df['close'] > df['BB_Upper'], -1, np.nan))\n",
    "    df['BB_signal'].fillna(-1, inplace=True)\n",
    "    df['BB_signal'] = df['BB_signal'].astype(int)\n",
    "    resampled_df = df.resample('4H').agg({\n",
    "        'Super_Trend_signal': 'last',\n",
    "        'EMA_signal': 'last',\n",
    "        'Hybrid_signal': 'last',\n",
    "        'Stochastic_signal': 'last',\n",
    "        'BB_signal': 'last'\n",
    "    }).dropna()\n",
    "\n",
    "    return resampled_df\n",
    "resampled_df = resample_signals(df)\n",
    "print(resampled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Inserting SIGNALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "def convert_timestamps(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    df['timestamp'] = df['timestamp'].astype(str)\n",
    "    return df\n",
    "conn = sqlite3.connect('indicators.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Indicators (\n",
    "    date_time TEXT PRIMARY KEY,\n",
    "    Super_Trend_signal INTEGER,\n",
    "    EMA_signal INTEGER,\n",
    "    Hybrid_signal INTEGER,\n",
    "    Stochastic_signal INTEGER,\n",
    "    BB_signal INTEGER\n",
    ")\n",
    "''')\n",
    "def insert_data(df):\n",
    "    df = convert_timestamps(df) \n",
    "    data = df.values.tolist()\n",
    "    cursor.executemany('''\n",
    "    INSERT OR REPLACE INTO Indicators (date_time, Super_Trend_signal, EMA_signal, Hybrid_signal, Stochastic_signal, BB_signal)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "    ''', data)\n",
    "    conn.commit()\n",
    "insert_data(resampled_df)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATABASE APPEND SIGNALS with LSTM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date_time  Super_Trend_signal  EMA_signal  Hybrid_signal  \\\n",
      "0  2020-01-01 00:00:00                  -1          -1             -1   \n",
      "1  2020-01-01 04:00:00                  -1          -1             -1   \n",
      "2  2020-01-01 08:00:00                   1          -1             -1   \n",
      "3  2020-01-01 12:00:00                  -1           1             -1   \n",
      "4  2020-01-01 16:00:00                  -1          -1             -1   \n",
      "\n",
      "   Stochastic_signal  BB_signal  LSTM_Signals  \n",
      "0                 -1         -1             1  \n",
      "1                 -1         -1            -1  \n",
      "2                 -1         -1             1  \n",
      "3                 -1         -1            -1  \n",
      "4                  1         -1            -1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "lstm_df = pd.read_csv('LSTM_signals.csv')\n",
    "conn = sqlite3.connect('indicators.db')\n",
    "cursor = conn.cursor()\n",
    "existing_table_name = 'indicators'\n",
    "cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{existing_table_name}';\")\n",
    "table_exists = cursor.fetchone()\n",
    "if table_exists:\n",
    "    cursor.execute(f\"PRAGMA table_info({existing_table_name});\")\n",
    "    columns = [column[1] for column in cursor.fetchall()] \n",
    "    if 'LSTM_Signals' not in columns:\n",
    "        cursor.execute(f\"ALTER TABLE {existing_table_name} ADD COLUMN LSTM_Signals INTEGER;\")\n",
    "        conn.commit()\n",
    "existing_df = pd.read_sql(f'SELECT * FROM {existing_table_name}', conn)\n",
    "if len(lstm_df) > len(existing_df):\n",
    "    lstm_df = lstm_df.head(len(existing_df))\n",
    "elif len(lstm_df) < len(existing_df):\n",
    "    padding_length = len(existing_df) - len(lstm_df)\n",
    "    padding_df = pd.DataFrame({'LSTM_Signals': [0] * padding_length})\n",
    "    lstm_df = pd.concat([lstm_df, padding_df], ignore_index=True)\n",
    "existing_df['index'] = existing_df.index\n",
    "lstm_df['index'] = lstm_df.index\n",
    "merged_df = pd.merge(existing_df, lstm_df[['index', 'LSTM_Signals']], on='index', how='left')\n",
    "merged_df.drop(columns='index', inplace=True)\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {existing_table_name}\")\n",
    "conn.commit()\n",
    "merged_df.to_sql(existing_table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending the GRU result in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date_time  Super_Trend_signal  EMA_signal  Hybrid_signal  \\\n",
      "0  2020-01-01 00:00:00                  -1          -1             -1   \n",
      "1  2020-01-01 04:00:00                  -1          -1             -1   \n",
      "2  2020-01-01 08:00:00                   1          -1             -1   \n",
      "3  2020-01-01 12:00:00                  -1           1             -1   \n",
      "4  2020-01-01 16:00:00                  -1          -1             -1   \n",
      "\n",
      "   Stochastic_signal  BB_signal  LSTM_Signals  GRU_Signals  \n",
      "0                 -1         -1             1           -1  \n",
      "1                 -1         -1            -1           -1  \n",
      "2                 -1         -1             1           -1  \n",
      "3                 -1         -1            -1           -1  \n",
      "4                  1         -1            -1           -1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "gru_df = pd.read_csv('gru_signals.csv')\n",
    "conn = sqlite3.connect('indicators.db')\n",
    "existing_table_name = 'indicators'\n",
    "existing_df = pd.read_sql(f'SELECT * FROM {existing_table_name}', conn)\n",
    "if len(gru_df) > len(existing_df):\n",
    "    gru_df = gru_df.head(len(existing_df))\n",
    "elif len(gru_df) < len(existing_df):\n",
    "    padding_length = len(existing_df) - len(gru_df)\n",
    "    padding_df = pd.DataFrame({'GRU_Signals': [0] * padding_length})\n",
    "    gru_df = pd.concat([gru_df, padding_df], ignore_index=True)\n",
    "existing_df['index'] = existing_df.index\n",
    "gru_df['index'] = gru_df.index\n",
    "merged_df = pd.merge(existing_df, gru_df[['index', 'GRU_Signals']], on='index', how='left')\n",
    "merged_df.drop(columns='index', inplace=True)\n",
    "merged_df.to_sql(existing_table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending the Fb Prophet result in DB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
